# ASR Distillation Configuration

data:
  index_path: "./data/index"
  cache_dir: "./data/cache"
  cache_size_gb: 100.0
  webdataset_output_dir: "./data/webdataset"
  shard_size_mb: 100
  
  storage:
    bucket: "your-bucket-name"
    endpoint: "https://oss-cn-beijing.aliyuncs.com"  # 阿里云OSS endpoint
    access_key_id: "your-access-key-id"
    access_key_secret: "your-access-key-secret"
    audio_prefix: "audio/"
    result_prefix: "results/"

pipeline:
  num_cpu_workers: 10
  num_gpu_workers: 1
  batch_size: 32
  max_concurrent_batches: 4
  object_store_memory: 1073741824  # 1GB
  checkpoint_interval: 1000
  
  cpu_worker_resources:
    num_cpus: 1

  gpu_worker_resources:
    num_cpus: 1
    num_gpus: 1

  # Stage-specific worker count configuration
  stage_workers:
    audio_download: 8        # IO-intensive stage
    audio_preprocessing: 6   # CPU-intensive stage
    vad_processing: 4        # Parallel processing stage
    segment_expansion: 4     # Medium CPU requirement
    feature_extraction: 6    # Medium CPU requirement
    batch_inference: 1       # GPU-intensive stage
    segment_aggregation: 2   # Lightweight processing
    post_processing: 2       # Lightweight processing
    result_writer: 1

# 多媒体处理配置
media:
  # 音频转换目标参数
  target_sample_rate: 16000
  target_channels: 1
  target_format: "wav"
  
  # FFmpeg配置
  ffmpeg_num_workers: 4  # 并行转换进程数
  ffmpeg_timeout: 300    # 转换超时时间(秒)
  ffmpeg_quality: "high" # 转换质量: low/medium/high
  
  # 缓存配置
  cache_enable: true
  cache_max_size_gb: 50
  cache_ttl_hours: 24
  
  # 性能设置
  chunk_size: 1048576  # 1MB chunks for large files
  max_file_size_mb: 500  # Maximum file size to process

audio:
  target_sample_rate: 16000
  max_duration: 30.0
  normalize: true
  remove_silence: false
  audio_format: "wav"
  
  features:
    feature_type: "mel_spectrogram"
    sample_rate: 16000
    n_fft: 400
    hop_length: 160
    n_mels: 80

# VAD语音活动检测配置
vad:
  model_path: "silero_vad.onnx"
  sampling_rate: 16000
  threshold: 0.4
  min_speech_duration_ms: 1500
  min_silence_duration_ms: 1000
  speech_pad_ms: 100
  batch_size: 32
  cache_enabled: true
  cache_dir: "./cache/vad"
  cache_max_size_gb: 10.0
  cache_ttl_hours: 24
  parallel_workers: 8

inference:
  model_name: "Qwen/Qwen3-Omni-30B-A3B-Instruct"
  tensor_parallel_size: 1
  max_num_batched_tokens: 8192
  max_model_len: 32768
  gpu_memory_utilization: 0.95
  trust_remote_code: true
  dtype: "auto"
  temperature: 0.01
  max_tokens: 8192
  top_p: 0.1
  repetition_penalty: 1.1
  max_num_seqs: 1
  limit_mm_per_prompt:
    image: 1
    video: 3
    audio: 3
  seed: 1234

writer:
  batch_size: 1000
  flush_interval: 10.0
  max_file_size_mb: 100
  output_format: "jsonl"
  compression: null
  async_upload: true
  retry_attempts: 3
  retry_delay: 1.0
  sync_mode: true  # 同步模式，默认为false（异步），设置为true可使用同步版本

monitoring:
  enable_prometheus: true
  prometheus_port: 8000
  metrics_interval: 5.0
  enable_gpu_monitoring: true
  enable_ray_monitoring: true
  checkpoint_interval: 1000
  checkpoint_dir: "./checkpoints"
  
  alert_rules:
    - name: "high_error_rate"
      severity: "warning"
      message: "High error rate detected"
      condition:
        type: "threshold"
        metric: "stages.inference.success_rate"
        threshold: 0.9
        operator: "<"
    
    - name: "high_memory_usage"
      severity: "critical"
      message: "High memory usage"
      condition:
        type: "threshold"
        metric: "system.memory_percent"
        threshold: 90
        operator: ">"